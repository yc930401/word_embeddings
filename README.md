# word_embeddings
Train word embeddings with IMDB dataset on keras and visualize the result.

## Introduction

Word embedding is very import in NLP with deep learning. Word embeddings provide a dense representation of words and their relative meanings. They are an improvement over sparse representations used in simpler bag of word model representations. Word embeddings can be learned from text data and reused among projects. They can also be learned as part of fitting a neural network on text data.

## Methodology

1. Load dataset and define a simple CNN model
2. Train the model and get embedding layer weights
3. Reduce two two dimension using PCA and visualize word embedding result

## Result
![embedding](/data/embedding.png) </br>

## Referrences
https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/ </br>
